### 컴파일과 프로세스
컴파일 언어: 개발자가 코드 작성 -> 컴파일(오류 미리 검출) -> 0과 1로된 기계어로 실행파일 만듬 
- 속도가 빠름
- c++,c, c#
인터프리터 언어: 개발자가 작성한 코드를 미리 기계어로 만들지 않고 1줄씩 실행하는 언어
- 실행할 때 오류 날 수 있고 속도도 느림
- js, python, ruby 등

### 프로세스
- code: 실행해야할 코드가 들어가야하는 영역
- data: 전역변수나 배열 들어가는 영역
- heap: 프로세스가 실행될 때 할당되는 메모리,실행 중 메모리 공간 할당할 수 있는 유동적인 공간
- stack: 프로세스가 실행될 때 할당되는 메모리, 지역변수나 함수 매개변수, 함수 리턴 주소 저장

전처리(#inclue, #define, 코드 주석 삭제) -> 컴파일(어셈블리어로 변경) -> 어셈블러(오브젝트 파일로 변경, 코드영역과 데이터 나눠져있음)
-> 링커(실행파일로 변경, 여러개의 오브젝트 파일을 하나로 합침,실행될 주소 매핑)
-> 실행하면 프로세스(프로그램의 코드영역과 데이터 영역 가져와 빈 상태의 힙과스택 만들어 줌)
-> PCB 만들어 관리 가능하게 만들고 프로그램 카운터를 생성한 프로세스의 첫번째주소로 만듦

### 중간정리
오늘날 컴퓨터: 폰 노이만 구조(cpu와 메모리, 편의성을 위한 보조장치(하드디스크, 마우스, 모니터,키보드))
컴퓨터가 부팅되면 하드디스크에있는 운영체제가 메모리에 올라옴, 프로그램을 실행하면 메모리에 올라감.
메모리에 올라간 프로그램을 프로세스라고 부르고 프로세스들은 실행시켜줄 cpu 를 기다림
운영체제가 공평하게 cpu 할당(cpu 스케쥴링)

### 메모리 종류
- 컴퓨터에는 여러 종류 메모리 존재
> 속도 빠름, 용량 작음, 가격 비쌈
> ^
> 레지스터: 가장 빠른 기억장소(CPU에 저장), 휘발성 메모리(32bit 레지스터 가지고 있으면 32bit cpu, 64bit 레지스터 가지고 있으면 64bit cpu), 메인메모리에 있는 값 레지스터로 가져와서 연산, 연산 완료되면 다시 메인메모리에 저장
> 캐시: 휘발성 메모리, 메인메모리에 있는 것을 레지스터로 그때그때 전송하면 느리니까 미리 사용할 거 같은 값 캐시에 저장(빠름 L1 > L2 > L3 > 메인메모리 > 느림)
> 메인메모리(RAM): 실제 운영체제와 다른 프로세스들이 올라가는 공간, 휘발성 메모리, 실행중인 프로그램만 올림
> 보조저장장치(HDD,SSD): 사무용 프로그램, 작업한 파일 등 저장, 위의 것들에 비해 가격 저렴하고 전원이 공급되지 않아도 저장되는 비휘발성 메모리.
> 
> 속도 느림, 용량 큼, 가격 쌈


### 메모리와 주소
메인메모리 = 메모리
오늘 날 컴퓨터: 폰 노이만 구조(모든 프로그램 메모리에 올려 실행)
-> 1바이트마다 구역을 나눠 숫자를 매긴 것: 주소
32bit CPU: 레지스터 크기 32bit, ALU, 버스도 32bit, CPU가 다룰 수 있는 메모리 4GB
64bit CPU: 다룰 수 있는 메모리 2^64 (한번에 처리할 수 있는 양 많기 때문에 빠름)

0번지부터 시작: 물리적 메모리
사용자가 접근하고자하는 주소 공간: 논리적 공간
운영체제는 특별해서 메모리 공간에 운영체제를 위한 공간 따로 만들어 둠.(사용자 프로세스가 운영체제에 접근x)
운영체제 공간과 사용자 공간을 나누는 경계 레지스터 둠. MMU는 만약 사용자 프로세스가 경계 레지스터 값을 벗어났는지 검사하고 강제종료
개발자는 프로그램이 실행될 주소 공간 고려하지 않고 개발. -> how: 어떤 프로세스든 0번지에서 시작된다고 가정하고 개발하니까(논리 주소)
cpu -> 메모리 관리자에게 100번지에 있는 값(논리적 메모리 주소) 가져오라고 하면 재배치 레지스터 값을 더해서 그 주소의 값(물리적 메모리의 주소) 가져옴
시작 주소 바껴도 재배치 레지스터 값만 바뀌면 유연하게 다시 매핑해서 정보 가져올 수 있음

### 메모리 할당방식
메모리보다 더 큰 프로그램 실행시키는 방법? 큰 프로그램을 잘라서 당장 실행시킬 것만 메모리에 올리고 나머지는 하드디스크 스왑영역에 저장
-> but 실제 메모리로만 실행하는 경우보다는 느림

1. 가변 분할 방식(연속 메모리 할당) -> 세그먼테이션
- 프로세스의 크기에 따라 메모리 나누는 방식
- 장점: 내부 단편화x(프로세스 크기에 맞게 할당)
- 단점: 외부 단편화 발생(남는 공간 발생)
-> 외부 단편화 공간들을 합쳐주는 조각모음 해야함(프로세스 일시정지 후 해야돼서 오버헤드 발생)
2. 고정 분할 방식(비연속 메모리 할당) -> 페이징
- 프로세스의 크기와 상관 없이 메모리 할당
- 장점: 오버헤드 적고 구현 간단
- 단점: 작은 프로세스도 큰 영역에 할당되는 내부 단편화 발생
-> 분할되는 크기 최소화해서 내부 단편화 최소화

3. 버디 시스템
- 2의 승수로 메모리 분할해 할당
- 남는 메모리 공간 최소화하고 승수로 메모리 할당해서 조각모음 편리


### 가상메모리 개요
- 컴퓨터마다 메모리 크기 다름
--> 가상메모리: 작은 메모리 크기로도 큰 크기의 프로그램 실행할 수 있음
- 프로세스는 메모리 관리자에게 요청해 메모리에 접근
- 가상 메모리는 이론적으로는 무한대 이지만 실제로는 cpu의 비트수와 연관 있음.
- 메모리 관리자 = 물리주소로 보는 영역 = 메모리+하드디스크 내 스왑 영역 -> 메모리나 스왑영역에 정보 저장
--> 물리메모리 어떻게 나눌지 부족한 물리메모리 어떻게 처리할지 프로세스 어떻게 배치할지 등을 처리해 복잡한 과정 거침

운영체제 영역을 제외하고 프로세스들에게 가변분할방식이나 고정 분할 방식을 이용해 프로세스들에게 메모리 할당
--> 일반적으로 세그먼테이션-페이징 혼용방식 사용
메모리 관리자는 물리주소와 논리주소 매핑테이블로 확인

### 세그멘테이션(배치정책)
함수나 모듈등으로 세그먼트 구성
사용자 프로세스,cpu가 바라보는 주소: 논리 주소
MMU(메모리 관리자) -> 세그멘테이션 테이블을 가지고 논리 주소를 물리 메모리 주소로 변환해서 몇 번 세그먼트인지 알아줌
- 세그먼트 번호를 통해 base address와 bound address 찾아냄
- 컨텍스트 스위칭 할 때마다 메모리 관리자 내 세그먼트 테이블 베이스 레지스터를 해당 프로세스의 것으로 값을 바꿔줘야 함
- bound address: 세그먼트 크기
- base address+ bound address= 물리주소
- 논리 주소가 bound address가 크면 메모리 침범한 것

-> 논리적 구조대로 메모리 할당해서 힙 코드 데이터 스택 등에 접근 편하지만 외부 단편화 발생

### 페이징(배치정책)
고정분할 방식 이용한 페이징
- 외부 단편화가 있는 세그멘테이션 보완하기 위해 고안
- 일정한 크기로 내눔
- 내부 단편화 발생
- 메모리 관리자는 페이지테이블 가지고 있음.
- 페이지 인덱스와 오프셋 정보 가지고 있음(invalid -> 스왑영역에 저장돼 있음) -> 페이지 번호가 인덱스
- 페이지 넘버 = 논리주소/페이지 크기 = 0
- 오프셋 = 논리주소%페이지 크기 = 1000

세그멘테이션(외부단편화 발생, 논리적 영역별로 나눔)과 페이징(내부단편화 발생, 페이지로 나누어 논리적으로 나눔, 페이지테이블 크기 적절하게 유지하는 것 중요)

### 페이지드 세그멘테이션
- 세그멘테이션+페이징 장점
- 논리적으로 영역 나눔(코드/데이터/힙/스택) + 메모리 동일 크기로 나눔
- 메모리접근권한: 메모리 특정 번지에 부여된 권한(읽기, 쓰기, 실행) -> 코드/데이터/힙/스택 별로 권한 다름
-- code: 읽기/실행(프로그램 그 자체라서 수정x)
-- data: 변수 저장, 읽기 권한 있고, 쓰기 권한 있거나 없거나, 실행 권한x
-- heap/stack: 읽기/쓰기 권한
- 메모리 접근 권한에 대한 검사는 가상주소 -> 물리주소로 변환될 때마다 일어남
- 페이지드 세그멘테이션: 세그멘테이션 테이블에서 권한 비트 추가/페이지넘버(base address)/페이지 개수(bound address)
--> 몇번 세그먼트인지 알아냄(해당 세그먼트가 메모리 접근권한을 위반하는지 확인), 페이지넘버로 페이지 테이블에 접근 프레임에 접근/만약 메모리에 없으면 스왑메모리에 접근
- 단점: 물리메모리에 접근하기 위해 메모리에 접근 2번(1. 세그멘테이션 테이블/2.페이지테이블 접근)

현대 운영체제에서는 페이징과 페이지드 세그멘테이션 기법 적절히 섞어서 사용

### 디맨드 페이징(가져오기 정책)
90% 시간이 10%의 코드에서 발생 -> 지역성 이론
1. 공간의 지역성: 현재 위치와 가까운 데이터에 접근할 확률 높음
2. 시간의 지역성: 최근 접근했던 데이터가 오래 전에 접근했던 데이터보다 접근할 확률 높음

디맨드 페이징: 조만간 필요할 것 같은 데이터를 메모리로 가져오고 필요하지 않을 것 같은 데이터는 스왑영역에 저장.
ex) 포토샵: 필터들 모두 메모리에 올리면 무거워지니까, 본 프로그램만 메모리에 올리고 외부 필터들은 사용자 요청 있을 때만 올리기

메모리 계층구조
- 레지스터(cpu 내에 있어 빠름), 캐시, 메인메모리, 보조저장장치(느림)
- 스왑영역은 보조저장장치에 있어 매우 느림

가상메모리 = 메인메모리+스왑영역
스왑인: 스왑영역 -> 메인메모리
스왑아웃: 메인메모리 -> 스왑영역

가상 주소 주어지면 메모리 관리자는 페이지 테이블 참조해서 물리메모리가 있는 프레임 알아내거나 스왑영역 위치 알아내야함.
페이지 테이블을이루고 있는 한 행을: 페이지 테이블 엔트리 라고 부름.

페이지 테이블 엔트리
- 접근비트: 페이지가 메모리에 올라온 후 데이터 접근이 있었는지 알려줌
- 변경비트: 페이지가 메모리에 올라온 후 데이터 변경이 있었는지 알려줌
- 유효비트: 물리메모리에 페이지가 있는지 알려줌(1: 스왑영역, 0: 물리메모리)
- 읽기/쓰기/실행비트: 접근 권한 비트

메모리 관리자는 페이지 테이블을 보고 메모리 프레임을 확인: 없으면 page fault 발생(프로세스 멈춤) -> 스왑영역에 있는 데이터가 메모리로 올라가는 작업(프로세스 다시 시작)
1. 스왑 필요없는 경우
2. 스왑 메모리 데이터 참조하는 경우 : 물리메모리 빈공간으로 가져옴(페이지 테이블의 유효비트 변경)
3. 물리메모리 꽉찼을 때 스왑메모리 데이터 참조할 때: 물리메모리에서 필요없는 것 스왑영역으로 이동 후 스왑메모리의 데이터를 물리메모리로 이동(유효비트 변경) -> 페이지 교체 알고리즘

### 페이지 교체 정책
메모리가 꽉 찼을 때 어떤 페이지를 스왑영역으로 보낼지 정하는 정책
원하는 데이터가 메모리에 없으면 page fault 발생 -> 해당 페이지를 스왑인해야되는데, 메모리가 꽉차면 스왑아웃을 해야하는데 이 방식을 정하는 것을 페이지 교체 정책이라고 함

1. 무작위 선택: 지역성 고려x 자주 사용되는 페이지가 선택될 수도 있기에 성능 좋지 않음
2. fifo: 가장 먼저 메모리에 올라온 페이지 교체, 자주 쓰여도 교체될 수 있지만, 구현간단하고 성능이 나쁘진 않아서 잘 쓰임
- 오히려 성능이 떨어지는 경우가 발생
3. optimum(최적): 가장 오랫동안 쓰이지 않을 페이지(구현 불가능) 선택
4. lru(leat recently used): 가장 최근에 사용 잘 안하는 페이지 교체: 시간 정보 저장하면 비트를 많이 필요해서, 접근 비트를 이용해서 lru에 근접하게 구현
- lru와 optimum이 가장 유사, 시간이 아주 많이 지나면 오버플로우 발생
- lru와 비슷한 clock algorithm: 일정 시간 간격마다 모든 페이지의 접근 비트를 0으로 초기화
- 페이지 원형으로 연결, 스왑영역으로 옮길 페이지를 포인터로 가리킴: 클락핸드 -> 참조하는 접근비트가 1이면 0으로 변경, 다음 페이지 가리킴, 접근페이지 0인페이지면 스왑아웃
- 접근 비트0, 변경 비트0 / 접근비트 0, 변경비트1/ 접근비트 1, 변경비트0 / 접근비트 1, 변경비트1 순으로 변경
- > 부득이하게 fifo 사용할 때 있음(하드웨어적으로 접근비트 지원하지 않는 경우)
5. 2차 기회 페이지 교체 알고리즘
- fifo 개선
- fifo 방식에서 자주 사용되면 기회 한번 더 줌(큐의 맨 뒤로 보냄) -> 수명 연장
- lru보다는 성능이 안좋고 fifo보다는 좋음

### 스레싱과 워킹셋
cpu 스케줄링의 목표: cpu 사용률 높이기: 멀티프로그래밍 정도 올리는 것(i/o 작업으로 프로세스 사용 할 수없을 때 다른 프로세스 사용(컨텍스트 스위칭))

but 문제: 멀티 프로그래밍 정도를 올리면? 제한된 물리메모리에 프로세스를 많이 올려야되고 스왑영역에 저장되는 프레임이 많아지고 page fault 많이 발생 -> cpu 사용률 떨어짐
cpu 사용률 올리기 위해 운영체제가 멀티 프로그래밍 정도를 올려버리는 경우 발생, cpu 사용률을 높이려했지만 오히려 떨어지는 상황 -> 스레싱
근본적인 원인: 메모리의 절대적인 크기가 작음 -> 해결 방안: 메모리 크기 늘림
스레싱이 발생하지 않으면 메모리 크기 늘려도 별 문제x

소프트웨어적으로 스레싱을 해결하는 방법?
한 프로세스 실행될 때 너무 많은 페이지 할당하면 다른 프로세스가 사용할 페이지 줄어듦, 너무 적은 페이지 할당하면 빈번한 page fault 발생 -> 일정량 할당하고 page fault 발생하면 페이지 더 많이 할당, 페이지 fault 너무 적게 발생하면 페이지 더 많이 할당
-> 프로세스에게 맞는 적절한 페이지수 할당
적절한 페이지 수 정했으면 어떤 페이지 유지할 지 정함
현재 메모리에 올라온 페이지는 다시 사용할 확률 높음: 워킹셋 -> 하나의 세트로 묶어서 메모리에 다시 올림(프로세스가 준비상태에서 실행상태가 되는 컨텍스트 스위칭 상태에 사용)