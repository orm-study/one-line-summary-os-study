[ Section 6 ] 쉬어가기
	1. 컴파일과 프로세스
		1) 프로그래밍언어 : 컴파일언어, 인터프리터 언어
			1-1) 컴파일 언어
				- 개발자의 코드를 컴파일이라는 과정을 통해 기계어로 실행파일을 만드는 것
				- C, C++, C#
				- 미리 기계어로 만드므로 속도가 빠름
			1-2) 인터프리터 언어
				- 실행 시 코드를 한줄씩 해석해 실행하는 언어
				- 컴파일에 비해 속도가 느리며, 미리 검사하지 않으므로 실행 시 오류 발생할 수 있음.
				- JS, Python, Ruby
		2) 프로세스의 메모리 영역
			2-1) CODE : 실행할 코드가 저장된 영역
			2-2) DATA : 전역변수나 배열이 저장된 영역
			2-3) STACK & HEAP : 프로세스 실행 시 할당되는 메모리
				- STACK : 지역 변수, 함수 관련 값들
				- HEAP : 실행 중 메모리 동적 할당
		3) 컴파일 과정
			3-1) test.c
			3-2) 전처리기
				- #으로 시작되는 전처리 구문 처리 ( #include, #define 등 )
				- 코드의 모든 주석 제거
			3-3) test.i
			3-4) 컴파일러 : C언어를 어셈블리어로 변환
			3-5) test.s
			3-6) 어셈블러 : 어셈블리어를 기계어로 변환하여 오브젝트 파일로 변환함.
			3-7) test.o : 오브젝트 파일은 코드영역과 데이터 영역으로 나뉘어져 있음.
			3-8) 링커
				- 모든 오브젝트 파일들을 하나의 코드영역과 데이터 영역으로 묶음.
				- 실제로 실행될 주소를 맵핑 시키며, .exe 파일을 생성함.
			3-9) test.exe : 이 파일을 실행하면 운영체제가 프로세스를 만듦
			3-10)  프로세스
				- 운영체제는 .exe의 코드/데이터 영역을 프로세스의 데이터/코드 영역으로 삽입
				- 프로세스 제어 블록(PCB)를 만들고, 프로그램 카운터를 코드 영역의 첫번재 주소로 설정함.

[ Section 7 ] 메모리
	1. 메모리 종류
		1) 메모리 종류
			- 레지스터, 캐시, 메인메모리(RAM), 보조저장장치(HDD, SSD)
			- 왼쪽일수록 속도빠름, 용량 작음, 가격 비쌈, 오른쪽일수록 속도느림, 용량 큼, 가격쌈.
		2) 레지스터( Register )
			- 가장빠른 기억장소로 CPU 내에 존재함.
			- 컴퓨터 전원이 꺼지면 데이터가 사라지는 휘발성 메모리임.
			- CPU 구분 시 32BIT / 64BIT 구분하는데 이는 레지스터의 크기를 의미함.
			- CPU 계산시 메모리에 있는 값을 레지스터로 가져와 계산 후 결과를 다시 메인 메모리에 저장함.
		3) 캐시
			- 메인 메모리와 레지스터 사이에 존재하는 메모리
			- 동작 속도 : 레지스터 >>> 메인 메모리
			- CPU가 계산할 데이터를 메인 메모리에서 미리 가져와 데이터를 저장하는 장소임.
			- 캐시는 L1, L2, L3..가 있으며 L1이 가장 빠름.
		4) 메인 메모리(RAM)
			- 실제 운영체제와 프로세스들이 올라가는 공간
			- 전원이 공급되지 않으면 데이터가 지워지는 휘발성 메모리
			- 동작속도 & 가격 : 메인 메모리(RAM) >>> 보조 저장 장치(HDD or SSD)
		5) 보조 저장장치( HDD & SDD )
			- 비휘발성 메모리이며, 데이터 저장장소로 사용함.

	2. 메모리와 주소
		1) 운영체제는 메모리 관리를 위해 1바이트 크기로 구역을 나눠 숫자를 매기는 데 이 숫자를 주소라고 함.
		2) 32BIT CPU는 레지스터, ALU, 데이터 이동버스 32BIT로 CPU가 다룰수 있는 메모리의 크기도 2의 32승으로 4GB임.
		3) 64BIT CPU는 레지스터, ALU, 데이터 이동버스 64BIT로 CPU가 다룰수 있는 메모리의 크기도 2의 64승으로 거의 무한대에 가까움.
		4) 물리주소 공간 : 메모리를 컴퓨터에 연결하면 0x0번지부터 시작하는 주소공간
		5) 논리주소 공간 : 사용자 관점에서 바라본 주소공간
		6) 메모리에는 운영체제와 수많은 프로세스가 존재하며, 운영체제를 위한 메모리 공간이 별도로 존재함.
		7) 운영체제의 보호를 위해 하드웨어적으로 운영체제 공간과 사용자 공간을 나누는 경계레지스터를 만듦.
			- 메모리 관리자가 사용자 프로세스가 경계레지스터 영역에 침범여부를 확인함.
		   	- 만약 프로세스가 경계레지스터 침범 시 강제로 프로세스 종료 시킴
		8) 절대 주소 : 실제 메모리의 주소로, 메모리 관리자가 바로본 주소
		9) 상대 주소 : 사용자가 바라본 주소
		10) 재배치 레지스터 : 프로그램의 시작 주소가 저장되어 있음.
			- 만약 사용자가 100번지 데이터를 요청하면, 재배치 레지스터의 4000번지와 합산하여 4100번지 주소에서 데이터 가져옴.
		
	3. 메모리 할당방식
		1) 메모리 오버레이 : 프로그램이 메모리보다 큰 경우 당장 실행할 부분만 메모리에 올리고, 나머지는 하드디스크의 스왑영역에 저장하는 기법
		2) 멀티 프로그래밍 환경에서의 메모리 관리 방법
			2-1) 가변 분할 방식 : 프로세스의 크기에 따라 메모리를 나누는 방식
			2-2) 고정 분할 방식 : 프로세스의 크기와 상관없이 메모리를 정해진 크기로 나누는 방식임.
		3) 가변 분할 방식
			3-1) 하나의 프로세스가 메모리의 연속된 공간에 할당되므로 연속 메모리 할당이라고 함.
			3-2) 가상 메모리 시스템에서는 세그멘테이션이라고 함.
			3-3) 장점 : 메모리가 낭비되는 공간인 내부 단편화가 없음.
			3-4) 단점 : 외부 단편화 발생
			3-5) 외부 단편화가 발생한 경우 조각 모음을 통해 해결가능하나, 프로세스를 일시정지 후 메모리 공간을 이동해야하므로 오버헤드가 발생함.
		4) 고정 분할 방식
			4-1) 하나의 프로세스가 메모리에 분산되어 할당되므로 비연속 메모리 할당이라고 함.
			4-2) 가상 메모리 시스템에서는 페이징이라고 함.
			4-3) 장점 : 구현이 간단하고 오버헤드가 작음.
			4-4) 단점 : 내부 단편화가 존재함.
		5) 버디 시스템
			5-1) 가변 분할 방식과 고정 분할 방식을 혼합대 단점을 최소화한 방식
			5-2) 버디 시스템은 이진수로 메모리를 분할해 프로세스를 메모리에 할당하는 방식
			5-3) 메모리 크기가 2048Byte이고, 500Byte 프로세스 메모리 할당 시 2의 승수 기준으로 500바이트보다 작은 값을 만날때까지 나눔.
				3번 나누면 256Byte이므로 512Byte 공간에 프로세스 할당함.
				- 내부 단편화는 12Byte로 작고, 외부 단편화의 문제를 해결하기 위한 조각모음도 쉬움.
		
[ Section 8 ] 가상메모리
	1. 가상메모리 개요
		1) 가상 메모리는 운영체제와 프로세스의 크기가 실제 메모리보다 크다면 컴퓨터에서 실행되지 않는 현상을 해결하기 위함.
		2) 가상 메모리의 크기 : 이론적으로는 무한대이나 실제는 물리메모리 크기와 CPU 비트수로 결정됨.
			ex) 32BIT CPU : 2의 32으로 약 4GB로 가상 메모리 크기와 동일함.
		3) 프로세스의 크기가 실제 물리 메모리보다 큰 경우 실행하는 방법
			- 가상 메모리 시스템은 물미 메모리 내용의 일부를 하드디스크에 있는 스왑 영역으로 옮기고 필요시 물리 메모리로 가져와 실행함.
		4) 동적 주소 변환( Dynamic Address Translation )
			- 메모리 관리자는 물리 메모리와 스왑 영역을 합쳐 가상 주소를 물리주소로 변환하는 것.
		5) 가상 메모리 시스템에서 프로세스에게 할당하는 방식은 가변 분할 방식을 이용한 세그멘테이션, 고정 분할 방식을 이요한 페이징이 있음.
		6) 세그멘테이션은 외부 단편화, 페이징은 내부 단편화 단점이 있어서 이 단점을 보완한 세이멘테이션 페이징 혼용 기법을 사용함.
		7) 메모리 관리자는 가상 주소와 물리 주소를 1대 1 맵핑 테이블로 관리함.
		
	2. 세그멘테이션(배치정책)
		1) 세그멘테이션은 힙 영역, 스택 영역, 코드 영역, 데이터 영역 등으로 구성함.
		2) 사용자와 프로세스, CPU가 바라보는 주소는 논리주소라고 함.
		3) 논리 주소를 물리 주소로 변환하는 방법
			3-1) 세그멘테이션 테이블에 저장된 Base Address와 Bound Address를 이용해 물리 주소를 계산함.
			3-2) 메모리 관리자는 Segment Table Base Register를 이용해서 물리 메모리 내의 세그멘테이션 테이블을 찾음.
			3-3) 세그먼터 번호를 인덱스로 Base & Bound Addrees( 세그먼트의 크기 의미 )를 찾음
			3-4) IF 논리주소 < 바운드 어드레스 → 논리주소 + 베이스 어드레스
				 IF 논리주소 > 바운드 어드레스 → 메모리 침법 에러 발생 → 프로세스 종료		 
			
	3. 페이징(배치정책)
		1) 논리 주소 공간 : 사용자와 프로세스가 바라보는 주소 공간
		2) 물리 주소 공간 : 실제 메모리에서 사용되는 주소 공간
		3) 페이징은 메모리 할당 시 정해진 크기의 페이지로 나눔
		4) 페이지 : 논리주소 공간을 일정한 크기로 균일하게 나눈 것.
		5) 프레임 : 물리주소 공간을 일정한 크기로 균일하게 나눈 것.
		6) 페이징의 주소 변환
			6-1) 메모리 관리자는 페이지 테이블을 가지고 있음.
			6-2) CPU 논리주소 전달 시 메모리 관리자는 페이지 테이블 베이스 레지스터(Page Table Base Register; PTBR)을 이용해서
			     물리 메모리에 있는 페이지 테이블를 찾고
			6-3) 페이지 테이블을 이용해 프레임 번호를 알아내고 오프셋을 이용해 물리주소로 변환함.
			6-4) 페이지 테이블에 Invalid 표시는 하드디스크의 스왑 영역에 저장되었다는 의미.
		7) 32비트 CPU 주소 변환 방법
			7-1) 2의 24승 바이트( 24비트 ) = 16MB인 페이지로 나누고, 2의 8승( 8비트 )은 페이지 번호를 나타냄.
			7-2) 페이지 넘버 구하는 공식 : 논리주소를 페이즈 크기로 나눈 몫 
			7-3) 오프셋 구하는 공식 : 논리주소를 페이즈 크기로 나눈 나머지 
			7-4) 페이지 넘버로 프레임 넘버 확인 후 오프셋을 더해 물리주소로 변환 완료함.

	4. 페이지드 세그멘테이션(배치정책)
		1) 세그멘테이션은 코드/데이터/스택/힙 영역을 세그먼트로 나눠관리하므로 다른 프로세스와 공유 및 각 영역별 메모리 접근 보호에 유리함.
		2) 메이징은 고정분할 방식이므로 메모리 효율적 관리가 가능함.
		3) 메모리 접근 권한 : 메모리의 특정 번지에 부여된 권한으로 읽기/쓰기/실행 총 3가지가 있음.
						메모리 접근 권한 검사는 가상 주소에서 물리주소로 변환 시마다 검사하면 만약 위배 시 에러 발생시킴.
		4) CODE : 읽기/실행 권한
		   DATA : 읽기/( 쓰기 ) 권한
		   HEAP : 읽기/쓰기 권한
		   STACK : 읽기/쓰기 권한
		5) 페이지드 세그멘테이션 기법
			- 세그멘테이션 테이블과 페이지 테이블을 이용함.
			- 세그멘테이션 테이블은 권한비트가 추가되고, 베이스 어드레스는 페이지 넘버로, 바운드 어드레스는 세그먼트의 페이지 갯수로 바꿈.
		6) 가상 주소가 들어오면 가상 주소를 이용해 세그먼트가 몇번인지 확인함.
		   세그멘테이션 테이블의 세그먼트 번호 참조와 메모리 접근 권한 위배 여부 확인함.
		   페이지 넘버로 페이지 테이블 접근하여 프레임 번호 확인
		   물리 메모리에 접근하여 페이지 갯수를 더해 물리주소를 구함.
		   만약 물리 메모리에 프레임이 없다면 스왑영역에서 물리 메모리를 가져옴.
	       → 이와 같이 물리 메모리 접근을 위해 메모리 두번 접근해야하는 것이 단점임.

	5. 디맨드 페이징(가져오기 정책)
		1) 컴퓨터 과학자 도널드 커노스는 90대 10 법칙을 발견함.
			1-1) 프로그램 실행 시 90%의 시간이 10%의 코드에서 보내는 것을 의미하고, 지역성 이론이라고 함.
			1-2) 첫번째 - 공간의 지역성 : 현재 위치에서 가까운 데이터에 접근할 확률이 높음.
			1-3) 두번째 - 시간의 지역성 : 현재 기준으로 가까운 시간에 접근했던 데이터가 먼 시간에 접근한 데이터보다 접근 확률이 높음.
			1-4) 조만간 쓰일 데이터만 메모리에 올리고 당분간 사용하지 않을 데이터는 스왑영역으로 보내 성능을 향상시키는 목적임.
		
		2) 디맨드 페이징
			- 곧 필요할 것 같은 데이터를 메모리로 가져오고 쓰이지 않을 것 같은 데이터는 스왑 영역으로 이동시키는 정책
			- 목적은 성능 향상을 위해 스왑 영역으로 데이터 이동 최소화
		3) 메모리 계층 구조
			3-1) 레지스터 : CPU 내에 존재하며, 한 사이클 안에 CPU 접근 가능
			3-2) 캐쉬 : 수 사이클 ~ 수십 사이클 내 CPU 접근 가능
			3-3) 메인 메모리 : 수백 사이클 내 CPU 접근 가능
			3-4) 보조 저장장치 : 수백만 사이클 내 CPU 접근 가능
		4) 스왑 인 : 스왑 영역에서 물리 메모리 데이터 가져오는 것
		5) 스왑 아웃 : 스왑 영역으로 물리 메모리 데이터를 보내는 것
		6) 페이지 테이블의 여러 종류의 비트들이 있으며, 페이지 테이블을 이루고 있는 한 행을 테이블 엔트리라고 부름.
		7) 접근 비트 : 페이지가 메모리에 올라온 후 데이터 접근 여부를 알려주는 비트
					메모리에 읽거나 실행작업을 했다면 1로 변경됨.
		8) 변경 비트 : 페이지가 메모리에 올라온 후 데이터 변경 여부를 알려주는 비트
					메모리에 쓰기 작업을 했다면 1로 변경됨.
		9) 유효 비트 : 페이지가 물리 메모리에 있는지 알려주는 비트.
					스왑 영역 : 1, 물리 메모리 영역 : 0
		10) 권한 비트 : 읽기/쓰기/실행에 대해 메모리 접근 권한 검사 비트
		11) Page Fault : 물리 메모리의 프레임을 찾을 때 물리 메모리에 없으면 페이지 펄트라는 인터럽트 발생함.
						 이 때, 스왑 영역에 접근하게 되고 해당 프로세스는 대기 상태가 됨. 
						 그리고 스왑 영역의 데이터가 물리 메모리로 스왑 인 되면 프로세스는 다시 작업 시작함.
		12) 스왑 인, 스왑 아웃을 할 때 어떤게 적절한지는 운영체제가 판단하며 이 판단하는 것을 페이지 교체 알고리즘이라고 함.
			
	6. 페이지 교체정책
		1) 방법_1 랜덤 선택 : 지역성 이론 미고려로 성능이 좋지 않으며, 거의 사용하지 않음.
		2) 방법_2 FIFO( First In First Out ) 메모리에 들어온지 가장 오래된 페이지 선택
			- 구현이 간단하고 성능이 꽤 좋으나, 자주 쓰이는 페이지가 교체될 수 있음.
		3) 방법_3 Optimum, 앞으로 가장 오랫동안 쓰이지 않을 페이지를 선택하는 방법 
			- 구현이 불가능한 이론적인 선택방법으로 다른 알고리즘과 성능 비교 시 참조용으로 사용됨.
		4) 방법_4 LRU(Least Recently Used)
			- 최근에 가장 사용을 적은 페이지를 선택하는 방법으로 지역성 이론 기반임.
			- Optimum과 가장 근접한 성능을 보이나 지역성 이론이 맞는 않는 경우 성능 저하됨.
			- 시간은 비트 소모가 크므로 접근 비트들을 이용해 LRU에 근접하게 구현함.
		5) 빌레이디 역설( Belady's Anomaly )
			- Page Fault 축소를 위해 메모리 늘려 프레임수를 증가하였으나 오히려 페이즈 폴트가 더 많이 발생하는 현상
			- FIFO 방식에서만 발생하고 LRU에서는 발생하지 않음.
		6) Clock Algorithm
			- LRU와 유사하게 구현하기 위해 고안된 알고리즘으로 접근비트 하나만 이용함.
			- 일정 시간 간격마다 모든 페이지의 접근 비트를 0으로 초기화함.
			- 스왑 영역으로 옮길 페이지를 포인터로 가르키는데 이 포인터를 클락 핸드라고 하며 시계 방향으로 돔.
			- 스왑 영역으로 옮겨야 하는 경우 접근 피트를 원형으로 연결하고 클락 핸드를 시계 방향으로 전환하면서 접근 비트가 0인 페이지를 찾음.
			- 접근 비트가 1인 경우 0으로 변경하면서 찾고 접근 비트가 0인 경우 스왑 영역으로 페이지 보냄.
		7) 2차 기회 교체 알고리즘.
			- FIFO의 단점을 개선한 알고리즘으로 FIFO 방식과 동일하나 페이즈 폴트 없이 페이지 접근 성농 시
			  해당 페이지를 큐의 맨 뒤로 이동시켜 수명을 연장시키는 방식임.
			- 성능 : LRU > 2차 기회 교체 알고리즘 > FIFO

	7. 스레싱과 워킹셋
		1) CPU 사용율을 높이기 위해 동시 실행되는 프로세스의 수를 올리는 것임.
		2) 그러나 프로세스가 증가할수록 스왑 영역에 저장된느 프로세스가 증가하게 됨.
		3) 이는 CPU 작업 시간보다 스왑 작업 시간이 더 길어지고 CPU 사용율이 적어짐.
		4) CPU 스케쥴러는 CPU 사용율을 높이기 위해 더 많은 프로세스를 메모리에 올리게 됨.
		5) 이를 반복하면 CPU 사용율이 0에 가깝게 됨
			→ 이를 스레싱이라고 함. 
		6) 스레싱의 근본적인 원인은 물리 메모리의 크기 부족
		7) 스레싱의 소프트웨어 해결 방법
			7-1) 프로세스를 Page Fault 발생 횟수에 따라 페이지 할당 수를 조절함.
			7-2) 너무 많은 페이지 할당 시 빈번한 페이즈 폴트가 발생하므로 페이지 수 할당량 높임.
			7-3) 페이즈 폴트가 너무 적게 발생하면 페이즈를 과하게 할당해 메모리 낭비로 판단하여 페이지 회수함.
			7-4) 7-2) 7-3) 반복하면 적절한 페이지 수 결정됨.
		8) 워킹 셋 : 현재 메모리에 올라온 페이지는 다시 사용할 확률이 높기 때문에 하나의 세트로 묶어서 메모리에 올리는 것
				   프로세스가 준비상태에서 실행 상태가 되는 컨텍스트 스위칭 시 사용됨.
