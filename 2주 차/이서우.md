## CPU 스케줄링 개요

### CPU 스케줄러

운영체제

### CPU 스케줄링

운영체제가 프로세스에게 CPU를 할당하고 해제하는 것

### CPU 스케줄링 시 스케줄러(운영체제)가 고려해야 할 사항

1. **어떤 프로세스에게 CPU 리소스**(사용권)를 줘야 하는가? (어떤 프로세스를 실행시켜야 하는가?)
2. CPU를 할당 받은 프로세스가 **얼마만큼의 시간동안** CPU를 사용해야 하는가?

### 프로세스 상태(생성, 준비, 실행, 대기, 완료)

1. 프로세스가 생성되면 준비 상태가 된다.
2. 준비 상태에서 CPU를 기다리고 있는 프로세스들은 CPU 스케줄러에 의해 실행 상태로 전환된다.
3. 실행 상태에 있는 프로세스는 **CPU 할당 시간이 다 됐을 때 다시 준비 상태로 전환**된다. **I/O 요청이 발생할 경우 대기 상태로 전환**된다.
4. 작업이 끝나면 완료 상태로 전환된다.

프로그램을 실행시키면 메모리에 프로세스가 생성된다. 각 프로세스에는 1개 이상의 스레드가 존재한다. 프로세스는 CPU를 차지하기 위해 운영체제의 명령을 기다린다.

### CPU Burst와 I/O Burst

CPU를 할당 받아 실행하는 작업을 CPU Burst라고 부르고, 입출력 작업은 I/O Burst라고 부른다.

## 다중 큐

- 프로세스가 대기하고 있는 준비(Ready), 대기(Waiting) 상태의 프로세스는 큐 자료구조로 관리된다.
- 준비 큐, 대기 큐는 여러 개의 다중 큐로 구성돼 있다.
- 큐에는 프로세스 정보를 가지고 있는 PCB가 들어간다.

### 준비 상태, 준비 큐

프로세스가 실행(Running) 상태에서 준비 상태로 돌아갈 때, 운영체제는 해당 프로세스의 우선순위를 보고 그에 맞는 준비 큐에 넣는다.

CPU 스케줄러는 준비 상태의 다중 큐에 들어있는 프로세스들 중에 적당한 프로세스를 선택해서 실행 상태로 전환시킨다.

### 대기 상태, 대기 큐

프로세스가 실행 상태에서 I/O 요청을 받아 대기 상태로 전환되면, I/O 작업 종류에 따라 분류된 큐에 들어간다.

예를 들어, 하드디스크 작업은 HDD 큐에 들어간다. 하드디스크 작업이 완료되어 인터럽트가 발생하면 HDD 큐에서 다시 꺼내 온다.

## CPU 스케줄링 목표

1. **리소스 사용률**
    - CPU 사용률을 높이는 것
    - I/O 디바이스 사용률을 높이는 것
2. **오버헤드 최소화**
    - 스케줄링을 위한 계산이 너무 복잡하거나, 컨텍스트 스위칭을 자주 발생시키면 배보다 배꼽이 더 커지는 상황 발생
3. **공평성**
    - 특정 프로세스에게만 CPU를 할당하도록 하지 않고, 모든 프로세스에게 공평하게 CPU를 할당
4. **처리량**
    - 같은 시간 동안 더 많은 처리를 할 수 있는 방법을 목표로 함
5. **대기 시간**
    - 작업을 요청하고 실제로 작업이 이뤄지는 데까지 대기하는 시간이 짧도록 하는 것
6. **응답 시간**
    - 대화형 시스템에서는 사용자의 요청에 빨리 반응하는 게 중요하기 때문 응답 시간이 짧은 방법을 목표로 함

## CPU 스케줄링 알고리즘 성능

스케줄링 성능은 **평균 대기 시간**으로 평가한다. 평균 대기 시간은 프로세스 여러 개가 실행돼야 할 때 그 프로세스들 모두가 실행되기까지 소요되는 대기 시간의 평균이다.

| **프로세스 1 (25초)** | **프로세스 2 (5초)** | **프로세스 3 (4초)** |
| --- | --- | --- |

각 프로세스의 Burst Time은 25초, 5초, 4초다.

프로세스 1이 먼저 들어온 프로세스라면 기다림 없이 바로 실행되기 때문에 대기 시간은 **0초**다.

프로세스 2가 대기한 시간은 **25초**다.

프로세스 3이 대기한 시간은 **30초**다.

**세 프로세스의 평균 대기 시간 (0 + 25 +30) / 3 = 18.3 초**

| **프로세스 3 (4초)** | **프로세스 2 (5초)** | **프로세스 1 (25 초)** |
| --- | --- | --- |

Burst Time이 짧은 프로세스 순으로 실행시키면 평균 대기 시간이 짧아진다.

**세 프로세스의 평균 대기 시간 (0 + 3 + 9) / 3 = 4.3 초**

## CPU 스케줄링 알고리즘

### FIFO(First In First Out)

- **스케줄링 큐에 들어온 순서대로 CPU를 할당하는 방식**
- 먼저 들어온 프로세스가 완전히 끝나야지만 다음 프로세스를 실행할 수 있음
- 프로세스의 Burst Time에 따라 성능(평균 대기 시간) 차이가 심하게 나기 때문에 현대 운영체제에서는 잘 사용하지 않고, 일괄 처리 시스템에서 사용(시분할 처리 시스템에서 사용하기 부적합)

**[장점]**

- 단순하고 직관적

**[단점]**

- 실행 시간이 짧고 늦게 도착한 프로세스가 실행 시간이 길고 빨리 도착한 프로세스의 작업이 종료되길 기다려야 함
- I/O 작업이 발생하면 CPU는 I/O 작업이 종료될 때까지 쉬고 있어야 하므로 CPU 사용률이 떨어짐

### SJF(Shortest Job First)

- **Burst Time이 짧은 프로세스를 먼저 실행하는 방식** (Burst Time이 짧은 프로세스를 먼저 실행시키면 평균 대기 시간이 짧이지기 때문)
- 이론적으로 FIFO보다 성능 우수
- 두 가지 문제로 인해 사용되지 않음

**[문제]**

- 어떤 프로세스가 얼마나 실행될지 예측하기 힘듦
- Burst Time이 짧은 프로세스가 중간에 계속 들어오면 Burst Time이 긴 프로세스의 실행 순서가 계속 밀림

### RR(Round Robin)

- **한 프로세스에게 일정 시간만큼 CPU를 할당하고 할당 시간이 지나면 강제로 다른 프로세스에게 일정 시간만큼 CPU 할당**
    - 강제로 CPU를 뺏긴 프로세스는 큐의 가장 뒷부분으로 밀려남
- 가장 단순한 FIFO 알고리즘의 단점을 해결
    - 단점은 먼저 들어온 프로세스가 종료돼야 다음 프로세스 실행 가능
- 프로세스에게 **CPU를 할당하는 일정 시간**을 **타임 슬라이스** 또는 **타임 퀀텀**이라고 부름
    - 타임 슬라이스 값에 따라 성능이 크게 달라짐
        - 타임 슬라이스가 큰 경우(무한대라고 가정)
            - FIFO 알고리즘과 같아짐
        - 타임 슬라이스가 작은 경우(1ms)
            - 여러 프로세스가 동시에 동작하는 것처럼 느껴질 수 있음
            - 컨텍스트 스위칭이 잦아져서 타임 슬라이스에서 실행되는 프로세스 처리량보다 컨텍스트 스위칭을 처리하는 양이 훨씬 커져서 배보다 배꼽이 더 커지는 상황 발생(오버헤드가 너무 큼)
        - 최적의 타임 슬라이스를 결정하는 방법
            - 사용자가 느끼기에 프로그램이 버벅이지 않고 동시에 실행되는 것처럼 느껴지면서 오버헤드가 너무 크지 않는 값을 찾는 것
        - Windows의 타임 슬라이스는 20ms
        - Unix의 타임 슬라이스는 100ms

### MLFQ(Multi Level Feedback Queue)

- 오늘날 운영체제에서 가장 일반적으로 쓰이는 CPU 스케줄링 기법
- **CPU 사용률과 I/O 사용률이 좋게 나오는 작은 크기의 타임 슬라이스를 선택**
- RR의 업그레이드된 알고리즘

<img width="583" alt="스크린샷 2024-09-22 오후 11 09 55" src="https://github.com/user-attachments/assets/d9312012-6f97-4795-bdba-aa3259297724">

1. 우선순위가 다른 여러 큐를 준비한다.
2. 우선순위가 높을수록 타임 슬라이스는 작고, 우선순위가 낮을수록 타임 슬라이스는 커진다.
3. Burst Time이 타임 슬라이스 크기를 오버해서 CPU를 강제로 뺏긴다면, 프로세스는 원래 있던 큐보다 우선순위가 낮은 큐로 이동된다.
4. 우선순위가 낮은 큐로 이동됐으니, 다음 실행부터 타임 슬라이스가 조금 더 커지게 된다.
5. 다음에도 Burst Time이 타임 슬라이스 크기를 오버해서 CPU를 강제로 뺏기면 계속해서 우선순위가 낮은 큐로 이동 시키면서 결국 타임 슬라이스가 무한초에 가깝게 할당되기 때문에 FIFO처럼 한번에 작업을 마칠 수 있게 된다.

**[CPU Bound Process]**

- 대부분의 시간을 CPU 연산에 사용하는 프로세스
- 가장 중요한 것은 **CPU 사용률과 처리량**

**[ I/O Bound Process]**

- 대부분의 시간을 I/O 작업으로 보내고 CPU 연산은 조금만 수행하는 프로세스
- 가장 중요한 것은 **응답 속도**
    - 키보드나 마우스 입력을 했는데 반응이 늦으면 사용자가 답답해할 수 있음
 

## 프로세스 간 통신

### 프로세스 간 통신

1. **한 컴퓨터 내에서 프로세스 간 통신**
    - 통신하려는 프로세스들이 하나의 **파일을 이용**해 읽고 쓰는 방법
    - 운영체제가 생성한 **파이프를 이용**해 데이터를 읽고 쓰는 방법
2. **서로 다른 네트워크의 컴퓨터 내에 있는 프로세스 간 통신**
    - 운영체제가 제공하는 **소켓 통신**
    - 다른 컴퓨터에 있는 함수를 호출하는 **RPC(원격 프로시저 호출)**

### 한 프로세스 내에서 스레드 간 통신

- 스레드는 코드, 데이터, 힙 영역을 공유하는데, **데이터 영역에 있는 전역 변수나 힙을 이용**하면 스레드 간 통신 가능

## 공유 자원과 임계 구역

### 공유 자원

프로세스 간 통신 시 공동으로 이용하는 변수나 파일을 공유 자원이라고 한다.

### 동기화 문제 발생 이유

1. 공유 자원은 각 프로세스의 접근 순서에 따라 결과가 달라질 수 있다.
2. 컨텍스트 스위칭을 하며 시분할 처리를 하기 때문에 어떤 프로세스가 먼저 실행되고 어떤 프로세스가 나중에 실행될지 예측하기 힘들다.

따라서 연산 결과를 예측하기 힘들고 여기서 발생한 문제를 동기화 문제라고 부른다.

### 임계 구역

여러 프로세스가 동시에 접근해서 사용하면 안 되는 영역을 임계 구역(Critical Section)이라고 한다.

### 경쟁 조건

공유 자원을 서로 사용하기 위해 경쟁하는 것을 경쟁 조건(Race Condition)이라고 한다.

### 상호 배제

임계 구역에서 발생하는 문제를 해결하기 위해 상호 배제(Mutual Exclusion) 메커니즘이 필요하다.

### 상호 배제 요구사항

1. 임계 영역에는 하나의 프로세스만 접근한다.
2. 동시에 여러 요청이 발생해도 하나의 프로세스만 접근을 허용한다.
3. 임계 구역에 들어간 프로세스는 최대한 빠르게 나와야 한다. (다른 프로세스들이 오래 기다리지 않기 위해)

## 세마포어

임계 구역에서 발생하는 문제를 해결하기 위해 공유 자원에 대한 접근을 제한하는 상호 배제 메커니즘 중 한가지다.

### 세마포어 동작

세마포어는 정수형 변수로 나타낸다.

세마포어 변수 값이 1 이상일 때만 변수 값을 1 감소 시키고 공유 자원에 접근할 수 있다. 세마포어 변수 값이 0이면 1 이상이 될 때까지 즉, 다른 프로세스가 공유 자원에 대한 작업을 완료할 때까지 대기한다.

### 뮤텍스와 세마포어 차이

뮤텍스와 세마포어의 차이는 공유 자원에 접근할 수 있는 프로세스의 개수다. 뮤텍스는 단 하나의 프로세스만 공유 자원에 접근할 수 있다.

### 세마포어 단점

wait()과 signal()를 다른 순서로 호출하면 세마포어를 잘못 사용하게 될 가능성이 있다.

## 모니터

세마포어의 단점을 해결한 상호 배제 메커니즘이다. 모니터는 운영체제가 처리하는 것이 아니라 프로그래밍 언어 차원에서 지원하는 방법이다.

### 모니터 예시

대표적으로 Java에서 모니터를 지원한다.

**synchronized** 키워드를 사용해서 해당 공유 자원을 동시에 여러 프로세스가 접근할 수 없도록 한다.

```dart
public class Health
{
	private int gealth = 100;
	
	synchronized void increase(int amount) {
		health += amount;
	}
	
	synchronized void decrease(int amount) {
		health -= amount;
	}
}
```

프로세스 A가 increase()를 실행 중일 때 프로세스 B는 increase()뿐만 아니라 synchronized가 붙은 decrease()도 실행할 수 없다.


## 데드락 (교착 상태)

여러 프로세스가 서로의 작업이 끝나길 기다리고 있어서 아무도 작업을 진행하지 못하는 상태를 데드락이라고 한다.

### 데드락 발생 원인

**공유 자원**

어떤 자원을 여러 프로세스가 공유하지 않는다면 교착 상태가 발생할 일이 없다.

### 데드락 발생 필요 조건

네 가지 중 한 가지라도 충족하지 않으면 데드락은 발생하지 않는다.

1. **상호 배제**
    - 어떤 프로세스가 리소스를 점유했다면 그 리소스는 다른 프로세스에게 공유되면 안 된다. (식사하는 철학자에서 포크가 이에 해당)
2. **비선점**
    - 어떤 프로세스가 리소스를 점유하고 있다면 다른 프로세스는 그 리소스를 빼앗을 수 없어야 한다. (철학자 A가 들고 있는 포크를 철학자 B가 뺏을 수 없는 것)
3. **점유와 대기**
    - 어떤 프로세스가 리소스 A를 가지고 있는 상태에서 리소스 B를 원하는 상태여야 한다. (왼쪽 포크를 손에 쥔 채로 오른쪽 포크를 기다리고 있는 상태)
4. **원형 대기**
    - 점유와 대기를 하는 프로세스들의 관계가 원형을 이루고 있어야 한다. (서로가 서로의 포크를 원하는 상황이 원형을 이루는 것과 같음)

### 식사하는 철학자 (데드락 설명 예시)
<img width="277" alt="스크린샷 2024-09-22 오후 11 15 33" src="https://github.com/user-attachments/assets/8b1ed424-6ecb-47c4-a33e-c0cf290aebaf">

1. 원형 탁자에 음식 5개, 포크 5개, 그리고 철학자 5명이 모였다.
2. 음식을 먹으려면 포크를 2개 사용해야 한다.
3. 한명의 철학자가 좌우에 있는 포크를 집어서 음식을 먹는다.
4. 그동안 다른 철학자들은 음식을 먹지 않고 깊은 생각을 한다. (인간이란 뭘까..)
5. 이런 식으로 한명씩 돌아가면서 식사를 하면 문제가 없다.

**[문제]**

1. 모든 철학자가 왼쪽에 있는 포크를 들었다.
2. 각자 오른쪽 포크도 들어야 하는데 이미 다른 철학자가 들고 있는 상태다.
3. 무한정 서로를 기다리는 교착 상태에 빠진다.

## 데드락 해결 방법

**회피**할 것인가? 발생 후 **해결**할 것인가?

### 교착 상태 회피(Deadlock avoidance) 방법

운영체제가 프로세스들에게 자원을 할당할 때 얼마나 할당하면 교착 상태가 발생할 수 있는지 파악하고, 발생하지 않는 수준의 자원을 할당한다.

### 안정 상태와 불안정 상태

교착 상태 회피는 **전체 자원 수**와 **할당된 자원 수**를 기준으로 안정 상태와 불안정 상태로 나뉜다.

불안정 상태에 있더라도 무조건 교착 상태에 빠지는 것은 아니다. 확률이 높아지는 것이다.

### 은행원 알고리즘(Banker’s algorithm)

교착 상태 회피를 은행이 대출을 해주는 것으로 표현한 알고리즘이다.

1. 은행이 1000만 원을 보유하고 있다고 가정한다.
2. 사업가 A가 은행에서 500만 원을 빌린다.
3. 사업가 B가 은행에서 400만 원을 빌린다.
4. 시간이 지나 은행은 사업가 A에게 돈을 갚으라고 말하는데, 200만 원만 더 빌려주면 그걸로 돈을 벌어서 갚는다고 한다.
5. 은행은 현재 100만 원밖에 없기 때문에 사업가 B에게 돈을 받아서 사업가 A에게 200만 원을 빌려주려고 한다.
6. 은행은 사업가 B에게 돈을 갚으라고 말하는데, 사업가 B도 200만 원만 더 빌려주면 그걸로 돈을 벌어서 갚는다고 한다.
7. 은행은 누구에게도 돈을 더 빌려주지 못하고, 빌려준 돈을 받지도 못하는 교착 상태에 빠진다.

은행은 위와 같은 상황을 피해기 위해 돈을 빌려줄 때 은행의 여윳돈과 사업가들에게 빌려준 돈들을 보고 대출 가능한 상황(안정 상태)인지 확인 후 빌려준다. 이것을 은행원 알고리즘이라고 한다.

### 운영체제에서 은행원 알고리즘을 구현하는 방법

1. 운영체제는 프로세스들에게 자원을 할당하기 전에 자신이 가지고 있는 전체 자원 수(**시스템 총 자원**)를 알고 있어야 한다.
2. 프로세스들은 각자 자신이 필요한 자원의 최대 개수(**최대 요구 자원**)를 운영체제에게 알려준다.

**[안정 상태]**

- 시스템 총 자원 14개
- 프로세스들에게 할당된 총 자원 12개
- 현재 사용 가능한 자원 2개

| **프로세스** | **최대 요구 자원** | **현재 할당된 자원** | **요청이 예상되는 자원** |
| --- | --- | --- | --- |
| P1 | 9 | 5 | 4 |
| P2 | 6 | 4 | 2 |
| P3 | 4 | 3 | 1 |
1. 은행원 알고리즘을 통해 각 프로세스가 현재 요구할 수 있는 요청이 예상되는 자원을 구한다.
2. 운영체제가 사용 가능한 자원 2개가 있고, 이 자원으로 요청이 예상되는 자원을 제공할 수 있다.
3. 만약 P1이 4개를 요청하면 현재 사용 가능한 자원이 2개이기 때문에 P1의 요청을 거부하고 P2의 요청을 받는다.
4. P2는 2개만 요청하기 때문에 사용 가능한 자원 2개를 전부 P2에게 할당한다. P2는 할당된 자원을 가지고 작업을 마친 후 6개를 반납한다.
- 현재 사용 가능한 자원 2 → 0 → 6개

| **프로세스** | **최대 요구 자원** | **현재 할당된 자원** | **요청이 예상되는 자원** |
| --- | --- | --- | --- |
| P1 | 9 | 5 | 4 |
| P2 | 6 | 4 → 6 → 0 | 2 → 0 |
| P3 | 4 | 3 | 1 |
5. 사용 가능한 자원이 6개로 늘어났기 때문에 P3가 요청한 1개와 P1이 요청한 4개를 전부 할당할 수 있다.

**[불안정 상태]**

- 시스템 총 자원 14개
- 프로세스들에게 할당된 총 자원 13개
- 현재 사용 가능한 자원 1개

| **프로세스** | **최대 요구 자원** | **현재 할당된 자원** | **요청이 예상되는 자원** |
| --- | --- | --- | --- |
| P1 | 9 | 7 | 2 |
| P2 | 6 | 4 | 2 |
| P3 | 4 | 2 | 2 |

현재 운영체제가 사용 가능한 자원이 1개다. P1, P2, P3가 요청할 수 있는 최대 요청인 2개를 충족하지 못한다.

이 상태를 불안정 상태라고 한다. 불안정 상태에 있더라도 모든 프로세스가 최대 자원을 요청하지 않는다면 교착 상태에 빠지지 않을 수 있지만 불안정 상태에 빠지지 않도록 유지하는 게 좋다.

### 교착 상태 검출 방법

은행원 알고리즘은 교착 상태를 피하는 좋은 방법이지만 비용이 비싸고 비효율적이기 때문에 교착 상태 발생은 허용하고 발생했을 때 해결하는 방법이 연구됐다.

1. **가벼운 교착 상태 검출**
    - **타이머**를 이용하는 방식
        - 프로세스가 일정 시간 동안 작업을 진행하지 않을 시 교착 상태가 발생했다고 간주하고 이를 해결
    - 교착 상태 해결 방법
        - 일정 시점마다 체크 포인트를 만들어 작업을 저장하고, 타임 아웃으로 교착 상태를 확인했다면 마지막에 저장한 체크 포인트로 롤백
2. **무거운 교착 상태 검출**
    - **자원 할당 그래프**를 이용하는 방식
        - 운영체제에서 각 프로세스가 어떤 자원을 사용하는지 지켜보고, 순환 구조 그래프 발생 시 교착 상태를 해결
    - 교착 상태 해결 방법
        - 교착 상태 검출 시 교착 상태를 일으킨 프로세스를 강제 종료하고, 다시 실행시킬 때 체크 포인트로 롤백
    - 장점
        - 가벼운 교착 상태 검출에서 발생할 수 있는 억울하게 종료되는 프로세스가 발생하지 않음
    - 단점
        - 운영체제가 지속적으로  자원 할당 그래프를 유지하고 검사해야 하기 때문에 오버헤드 발생
